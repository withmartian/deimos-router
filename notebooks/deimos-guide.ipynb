{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702cb18f-6032-4d03-bb3b-da8f4bdc0cf4",
   "metadata": {},
   "source": [
    "# Deimos Router\n",
    "\n",
    "Deimos is the smallest, ugliest moon of Mars.\n",
    "\n",
    "Deimos is also the smallest, dumbest way to do routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dade040-5d4d-4d1b-a800-091973ab48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deimos_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f036e4f9-3061-4fb8-a31b-417931dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deimos_router import Router, register_router, chat\n",
    "from deimos_router.rules import TaskRule, AutoTaskRule, CodeRule, CodeLanguageRule, NaturalLanguageRule, MessageLengthRule, ConversationContextRule, Rule, Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7434f-ba3e-4154-807a-1cbc293e0328",
   "metadata": {},
   "source": [
    "## Basic Usage - Task Based Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7122b-ca0c-4d4a-baf0-fa395bbdf45f",
   "metadata": {},
   "source": [
    "A Router uses one or more Rules to select a model. The simplest Rule is TaskRule, which maps task names to models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c16b786-c72b-4aea-b56b-1f0168ccffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskRule('task-based-routing', {'coding': 'openai/gpt-5', 'creative': 'openai/gpt-4o', 'simple': 'openai/gpt-5-nano'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskRule(\n",
    "    name=\"task-based-routing\",\n",
    "    triggers={\n",
    "       'coding': 'openai/gpt-5',\n",
    "       'creative': 'openai/gpt-4o',\n",
    "       'simple': 'openai/gpt-5-nano'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafdefd0-603d-4aac-b5fc-7d437a7cbc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('my-first-router', rules=['deimos/rules/task-based-routing'], default='openai/gpt-4o-mini')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "   name=\"my-first-router\",\n",
    "   rules=[\"deimos/rules/task-based-routing\"],\n",
    "   default=\"openai/gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace38270-a991-4ff6-a0f4-d797a20d7df4",
   "metadata": {},
   "source": [
    "To use a Router, make a call to `chat.completions.create`, as if it were a call to OpenAI's SDK, and specify the router as the model.\n",
    "\n",
    "For simple task-based routing, include the task name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e28bc9-23b5-4d1d-9eee-8faf8c6aedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number with 0-indexing:\n",
      "      F(0) = 0, F(1) = 1, F(2) = 1, ...\n",
      "    Uses fast doubling (O(log n) time).\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int) or n < 0:\n",
      "        raise ValueError(\"n must be a non-negative integer\")\n",
      "\n",
      "    def _fib(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return (0, 1)\n",
      "        a, b = _fib(k >> 1)\n",
      "        c = a * (2 * b - a)\n",
      "        d = a * a + b * b\n",
      "        if k & 1:\n",
      "            return (d, c + d)\n",
      "        else:\n",
      "            return (c, d)\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response = chat.completions.create(\n",
    "   model=\"deimos/my-first-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b713-71df-4584-b305-4115e89b4181",
   "metadata": {},
   "source": [
    "Details about the routing decision can be found in the response at `._deimos_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ca7ab1-deec-43fb-a856-675687acebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'my-first-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'TaskRule',\n",
       "   'rule_name': 'task-based-routing',\n",
       "   'rule_trigger': 'coding',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4453-abc1-4850-86e7-56d699d65cbc",
   "metadata": {},
   "source": [
    "## AutoTask Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6b54-afde-4e92-918b-544bbc535300",
   "metadata": {},
   "source": [
    "An `AutoTaskRule` is created in the same way as a `TaskRule`, but the task is determined by a call to a small language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a96242-92fa-495c-a269-e9a8163ebae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoTaskRule('auto-task-rule', {'creative writing': 'openai/gpt-4o', 'writing code': 'openai/gpt-5', 'informational': 'openai/gpt-5-mini', 'haiku composition': 'openai/gpt-5-nano'}, default=None, llm_model='openai/gpt-5-nano')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"creative writing\" : \"openai/gpt-4o\",\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"informational\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e90e8f-19cc-4849-9336-683fbe65443d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('auto-router', rules=['deimos/rules/auto-task-rule'], default='openai/gpt-4o-mini')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "    name = \"auto-router\",\n",
    "    rules = [\"deimos/rules/auto-task-rule\"],\n",
    "    default=\"openai/gpt-4o-mini\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b239d0-38f0-4bf3-a404-2020d8780206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number using fast doubling.\n",
      "    0-indexed: fib(0)=0, fib(1)=1, fib(2)=1, ...\n",
      "    Raises ValueError for negative n.\n",
      "    Runs in O(log n) time.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be non-negative\")\n",
      "\n",
      "    def _fib(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return (0, 1)\n",
      "        a, b = _fib(k >> 1)  # a = F(k), b = F(k+1)\n",
      "        c = a * ((b << 1) - a)  # F(2k)\n",
      "        d = a * a + b * b       # F(2k+1)\n",
      "        if k & 1:\n",
      "            return (d, c + d)\n",
      "        else:\n",
      "            return (c, d)\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response1 = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3492f8f-86a9-4791-a306-27f5d5f02d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'writing code',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263d7d03-50b7-4f2f-b692-727e5ed4085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç ‚ã®æ˜Ÿ\n",
      "é¢¨ãŒç«æ˜Ÿã‚’\n",
      "æºã‚‰ã™ç ‚\n"
     ]
    }
   ],
   "source": [
    "haiku = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a short japanese poem about mars, and follow the syllable count 5, 7, 5\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3f649b-aacb-4dec-9a74-e8ca115cb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde49483-d23d-4774-8688-e177ccec95a3",
   "metadata": {},
   "source": [
    "## Code / Not code Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e4391-887e-4164-9145-2cf91a5d7cd5",
   "metadata": {},
   "source": [
    "The `CodeRule` is a very simple rule that determines whether a prompt contains code and routes based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff4960c-efc8-41e0-a822-61e002e230a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('code-nocode-router', rules=['deimos/rules/code-or-not-code'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = \"openai/gpt-5\",\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-nocode-router\",\n",
    "    rules = [\"deimos/rules/code-or-not-code\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e066e5-93ca-4b93-a0cd-2d46ee0c9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youâ€™re using exponentiation (**) instead of multiplication. Use the * operator.\n",
      "\n",
      "Corrected code:\n",
      "```\n",
      "def multiply(x, y):\n",
      "    return x * y\n",
      "```\n",
      "\n",
      "Example:\n",
      "- multiply(3, 4) -> 12\n",
      "- multiply(2, 5) -> 10\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Debug this:\n",
    "```\n",
    "def multiply(x, y):\n",
    "    return x**y\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_1 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa69ce97-da19-4b47-80c0-23670255fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a63dcc2-a479-42f1-9504-5cb09256c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars has two small moons, Phobos and Deimos. Of the two, Phobos is generally considered the smaller and less aesthetically appealing. Phobos is heavily cratered, irregularly shaped, and has a very rugged surface, which contributes to its \"ugly\" appearance compared to other moons in the solar system. It is the larger of the two Martian moons but still quite small at about 22.4 kilometers in diameter. Its close orbit around Mars and its dark, dusty surface add to its unique and rather stark appearance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the smallest, ugliest moon of Mars?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_2 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471b406c-8d5a-4b1f-be94-60a4d0cb43db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_2._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce564b-3e21-4037-bf1d-ef00974c9097",
   "metadata": {},
   "source": [
    "## Code Language Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d74a7c-8067-4299-af77-878bedc65931",
   "metadata": {},
   "source": [
    "To route based on programming language, use a CodeLanguage rule.\n",
    "\n",
    "This rule uses regex to classify among several popular languages, and then falls back to a small language model call to determine language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3137e1d6-9037-4e35-96f4-19937eaa54ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('code-lang-router', rules=['deimos/rules/code-lang-rule'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-lang-router\",\n",
    "    rules = [\"deimos/rules/code-lang-rule\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4b84c7-9c6f-457f-bc9a-f145c12e5c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function calculates the nth Fibonacci number using the iterative method where the Fibonacci numbers are generated by repeatedly adding the two previous numbers in the sequence. It uses bitwise operations to efficiently calculate the Fibonacci number at position n.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "179ee0db-bb65-47ed-9062-7cee30f4eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b1e0a6-21a2-4655-9119-baaf0f8630c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a SQL query. It returns every column for every row in the table named people where the column name equals \"john\".\n",
      "\n",
      "Line-by-line:\n",
      "- SELECT * â€” select all columns.\n",
      "- FROM people â€” from the table called people.\n",
      "- WHERE name = \"john\" â€” filter rows to those whose name equals \"john\".\n",
      "\n",
      "Notes and gotchas:\n",
      "- It produces a result set (zero or more rows); it does not modify the database.\n",
      "- Standard SQL uses single quotes for string literals: WHERE name = 'john'. In some databases double quotes denote identifiers, and in others (e.g. default MySQL) double quotes may act like single quotes; behavior depends on the DBMS.\n",
      "- Case-sensitivity depends on the column collation. For a case-insensitive match use e.g. WHERE LOWER(name) = 'john' or (in PostgreSQL) WHERE name ILIKE 'john'.\n",
      "- For partial matches use LIKE (e.g. WHERE name LIKE '%john%').\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does code do?\n",
    "```\n",
    "SELECT *\n",
    "FROM people\n",
    "WHERE name = \"john\"\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b7c6a5-c8fb-4819-9c23-1099a64a8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'sql',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994841eb-e468-4447-ad97-de65062189d6",
   "metadata": {},
   "source": [
    "## NaturalLanguageRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f11a8f-8462-4f29-aa3b-55c72d808ac8",
   "metadata": {},
   "source": [
    "To route based on the language of the request (English, French, Spanish, etc), use a NaturalLanguageRule. This calls a small language model to detect the language. Specify language:model mapping using the two-letter ISO language code (`EN`, `FR`, `ES`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75580c2b-bd8d-49c2-a8c9-c1929bf420f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('nat-lang-router', rules=['deimos/rules/nat-lang-rule'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"EN\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"nat-lang-router\",\n",
    "    rules = [\"deimos/rules/nat-lang-rule\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61d51600-d9a8-4fae-91a3-aafe1d629abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the grammar teacher go to jail? \n",
      "Because she kept committing homonyms!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me a joke about language.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65dd159d-c716-450a-bc05-125dc919d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'EN',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4baa8df-1f1f-42a3-8dd9-082d57759356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un clÃ¡sico corto:\n",
      "\n",
      "Un lingÃ¼ista entra en un bar. El camarero le pregunta: \"Â¿QuÃ© quiere tomar?\" El lingÃ¼ista responde: \"Depende del contexto\".\n",
      "\n",
      "Y otro rÃ¡pido:\n",
      "\n",
      "â€”Â¿Por quÃ© los sinÃ³nimos no pelean?  \n",
      "â€”Porque siempre estÃ¡n de acuerdo en algo.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "CuÃ©ntame un chiste sobre el lenguaje.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8880aeb8-ae95-4a00-b1cc-a5e0ddb972d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'ES',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faca0dd-9586-4f17-9fcd-6b54f6c3b283",
   "metadata": {},
   "source": [
    "## MessageLengthRule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7ccc5-e025-461f-af9d-ec0e0f52ee1d",
   "metadata": {},
   "source": [
    "The MessageLengthRule selects one of three models based on length (in tokens) of the user message. \n",
    "\n",
    "- short: below the `short_threshold`\n",
    "- medium: between the `short_threshold` and the `long_threshold`\n",
    "- long: above the `long_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a468af6e-b0db-4fb2-8596-50c0ef5bcd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('length-router', rules=['deimos/rules/msg-len'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MessageLengthRule(\n",
    "    name = \"msg-len\",\n",
    "    short_threshold = 50,\n",
    "    long_threshold = 200,\n",
    "    short_model = \"openai/gpt-5-nano\",\n",
    "    medium_model = \"openai/gpt-5-mini\",\n",
    "    long_model = \"openai/gpt-5\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"length-router\",\n",
    "    rules = [\"deimos/rules/msg-len\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "359b0d50-2e00-419f-93e0-5f0890d99bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars is generally described as reddish-orange, often called the Red Planet. This coloration comes from iron oxide (rust) on its surface and dust in the atmosphere. In some views it can look more orange-red, and its polar caps appear white.\n"
     ]
    }
   ],
   "source": [
    "short_prompt = \"What color is Mars?\"\n",
    "\n",
    "short_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": short_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(short_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0afba91b-d472-4e5b-920f-8bbe2a708a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'msg-len',\n",
       "   'rule_trigger': 'short_message_5_tokens',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de8ef63-5fe4-4af1-8017-9347e422611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: The TokenTales SkyRail â€” â€œStories that Flyâ€\n",
      "\n",
      "Concept in one line\n",
      "An aerial, slow-moving gondola ride that combines a cable-suspended scenic tram, a chooseâ€‘yourâ€‘ownâ€‘adventure storytellerâ€™s toolkit (physical tokens), large-scale puppet theater and adaptive live music â€” so each trip becomes a unique, communal story told in motion.\n",
      "\n",
      "How it looks\n",
      "- The line and station feel like a giant open storybook: paperâ€‘textured canopies, warm lantern light, and carved wooden shelves with glowing token bins.\n",
      "- Gondola pods are cradleâ€‘like â€œorigami boatsâ€ of painted timber and glass (4â€“6 passengers each), suspended from a graceful cable that winds above a theatrical landscape of miniature worlds.\n",
      "- Below and alongside the line are modular stage-sets â€” forests with mechanical trees, an â€œoceanâ€ of reflective ribbons, clockwork cities, a mountain plateau with puppet giants, and hidden nooks for actors and animatronics to peek out.\n",
      "- Lighting rigs, scent emitters, subtle wind and mist effects, projection mapping and roaming drones integrate with hand-operated puppetry on the ground to create layered scenes.\n",
      "\n",
      "How it works â€” step by step\n",
      "1. Choose your tokens: before boarding, each guest picks 3â€“5 wooden tokens from the Story Shelf. Each token is an archetype or element (e.g., Hero, Trickster, Moon, Forbidden Door, Compass, Songbird, Storm, Map, Mirror, Timepiece). Tokens are tactile, painted and slightly different sizes so kids can read them by shape alone.\n",
      "2. Register your sequence: slide your tokens into the podâ€™s console in the order you want. The podâ€™s screen shows a playful â€œstory scoreâ€ that interprets token order into themes (bravery, mischief, memory, etc.).\n",
      "3. Liftâ€‘off and weave: as the pod glides along the cable, the SkyRailâ€™s show engine (a narrative director computer + live stage team) translates each token sequence into a tailored run of scenes. Animatronics rearrange small set pieces, puppeteers bring characters to life, projections change the sky, scent cues and wind mists match the mood, and a live or AI-assisted orchestra (on-site musicians plus adaptive audio) composes an evolving soundtrack to match.\n",
      "4. Real-time audience control: the tokens in every pod are networked to the show system. When multiple pods choose aligned elements (e.g., many pods pick â€œStormâ€), the whole route may darken and the music swells. If a single pod opts for â€œSecret Garden,â€ a hidden corner of the set opens only for that pod to see â€” a tiny puppet reveals a token-sized keepsake.\n",
      "5. Interactions on the ground: puppeteers and actors in costume occasionally interact with the pods â€” waving, passing a rope ladder for a playful â€œrescueâ€ scene, or slotting a dramatic flourish in response to a childâ€™s shout. Large bunraku-style puppets and kinetic sculptures perform sweeping motions visible from above.\n",
      "6. The finale: the last token triggers a â€œbookbindingâ€ finale â€” projection paints a floating book page visible from the pod that shows snapshots from the rideâ€™s story. When you disembark, a small printed story scroll is waiting (or a QR code to download a personalized animated short and the soundtrack), summarizing the tale you created.\n",
      "\n",
      "What makes it magical and fun\n",
      "- Tactile storytelling: choosing physical tokens engages children and adults alike; the causeâ€‘andâ€‘effect of slotting a token and then seeing it change the world around you feels like real magic.\n",
      "- Collective play: the ride is both personal and social. Your podâ€™s choices matter, but when multiple riders sync up, the world responds in bigger ways. Friends and strangers can coâ€‘author a bigger story on the fly.\n",
      "- Multiâ€‘sensory immersion: sight, sound, scent, touch and gentle motion combine to form a vividly memorable experience thatâ€™s entirely nonâ€‘thrill (suitable for all ages) but endlessly replayable.\n",
      "- Live theater + adaptive tech: the blend of live puppetry and actors with AI-assisted music and projection means no two rides are precisely the same; performers can improvise with guests, giving a warm human heartbeat to the tech.\n",
      "- Keepsakes and replayability: the printed scroll/QR download lets families relive the adventure â€” and try different token combos next time to discover new twists and endings.\n",
      "\n",
      "Sample ride moments\n",
      "- Insert â€œHero, Map, Nightâ€ â†’ Your pod watches a silhouetted hero chase fireflies through a moonlit clock-town; a gentle breeze brings the smell of pine; a puppet owl drops a tiny lantern onto the pod railing.\n",
      "- Insert â€œTrickster, Mirror, Stormâ€ â†’ Paper boats appear on a mirrored pool below, reflections misbehave, and the soundtrack hops into playful syncopation while a puppet fox rearranges the scene.\n",
      "- Many pods choose â€œSongbirdâ€ at once â†’ The whole route bursts into birdlike harmonies; projectors paint lyric ribbons across the sky and a chorus of hidden pipes answers.\n",
      "\n",
      "Accessibility and safety\n",
      "- Slow-moving, accessible gondolas with space for wheelchairs.\n",
      "- Visual and audio cues are complemented by tactile tokens and haptic feedback in the seats.\n",
      "- All effects are nonâ€‘invasive, adjustable for sensory-sensitive guests.\n",
      "\n",
      "Why DreamTopia needs it\n",
      "TokenTales SkyRail is the parkâ€™s manifesto attraction: it celebrates imagination as a communal craft, blends tradition (puppetry, books) with modern storytelling tech, and gives guests agency â€” not just to experience a ride, but to co-create a small, ephemeral world.\n",
      "\n",
      "Poster tagline/slogan\n",
      "TokenTales SkyRail â€” Catch a Story. Let It Carry You.\n"
     ]
    }
   ],
   "source": [
    "medium_prompt = \"Imagine youâ€™ve just been hired as the Chief Imagination Officer for a brand-new amusement park called DreamTopia. Your first assignment is to design the parkâ€™s most unusual and delightful attraction, something that no other park has ever seen before. It should combine at least two completely different ideas (for example: a roller coaster made of books, or a water slide that doubles as a musical instrument). Please describe the attraction in detail: how it looks, how it works, and what makes it magical or fun. End with a short tagline or slogan that could go on the parkâ€™s posters.\"\n",
    "\n",
    "medium_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": medium_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(medium_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42ed9e93-b099-4325-aa43-199fd74d1687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'msg-len',\n",
       "   'rule_trigger': 'medium_message_119_tokens',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed112c-6ab6-4a3e-afec-5b225ed79150",
   "metadata": {},
   "source": [
    "## ConversationContextRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353b465-be4a-4e13-902b-93483ce84399",
   "metadata": {},
   "source": [
    "ConversationContextRule selects model based on the number of back-and-forth messages in a conversation, classifying a conversation as new, developing, or deep.\n",
    "\n",
    "- new conversation: less than `new_threshold` number of messages\n",
    "- developing conversation: between `new_threshold` and `deep_theshold` number of messages\n",
    "- deep conversation: longer than `deep_threshold` number of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e3c444b-d09f-4cb9-83a5-438a6c13c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('context-router', rules=[ConversationContextRule('conv-context-rule', 3, 10, 'openai/gpt-5-nano', 'openai/gpt-4o-mini', 'openai/gpt-4o')], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_rule = ConversationContextRule(\n",
    "    name = \"conv-context-rule\",\n",
    "    new_threshold = 3,\n",
    "    deep_threshold = 10,\n",
    "    new_model = \"openai/gpt-5-nano\",\n",
    "    developing_model = \"openai/gpt-4o-mini\",\n",
    "    deep_model = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"context-router\",\n",
    "    rules = [context_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3221777a-4ce9-48e9-9120-09edbc5d30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fun fact: From Deimos, Mars would dominate the skyâ€”Mars would appear about 16 degrees across (roughly 30 times the Moonâ€™s apparent size from Earth). For contrast, Deimos itself is tiny (about 12 kilometers across) and potato-shaped, and itâ€™s tidally locked to Mars, so the same face always points toward the planet.\n"
     ]
    }
   ],
   "source": [
    "new_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Tell me the funnest fact about Deimos (the moon, not the god).\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(new_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9292e1b-2ee0-4f42-ba31-cf0d7c805229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'context-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'ConversationContextRule',\n",
       "   'rule_name': 'conv-context-rule',\n",
       "   'rule_trigger': 'new_conversation_1_messages_62_chars',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "022cbed9-2c83-4954-bd0c-57d6826cd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hi there! Can you help me come up with a fun name for a coffee shop?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Of course! How about 'Bean There, Done That'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Haha, thatâ€™s clever. Can you give me a couple more options?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Sure! Some other ideas: 'Daily Grind CafÃ©' and 'Perk Up Coffeehouse.'\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Nice! I like 'Perk Up.' Can you suggest a tagline to go with it?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"How about: 'Perk Up â€” Where Every Cup Sparks Joy'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Perfect, thatâ€™s exactly what I was looking for. Thanks!\"\n",
    "    }\n",
    "  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b257399-d65c-4139-a1f7-f4368210850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youâ€™re welcome! Iâ€™m glad you liked it. If you need any more help or ideas, feel free to ask. Enjoy your coffee shop!\n"
     ]
    }
   ],
   "source": [
    "developing_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=conversation,\n",
    ")\n",
    "\n",
    "print(developing_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2655be2-7a4d-4c51-a3bd-124eb2076081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'context-router',\n",
       " 'selected_model': 'openai/gpt-4o-mini',\n",
       " 'original_model_field': 'openai/gpt-4o-mini',\n",
       " 'explain': [{'rule_type': 'ConversationContextRule',\n",
       "   'rule_name': 'conv-context-rule',\n",
       "   'rule_trigger': 'developing_conversation_7_messages_410_chars',\n",
       "   'decision': 'openai/gpt-4o-mini'}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developing_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544687a-ded6-4384-b7cf-aa4f8bfffd8b",
   "metadata": {},
   "source": [
    "## Custom Rule Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a7a8d-dc7c-4695-94e8-65b40e008bfe",
   "metadata": {},
   "source": [
    "You can create your own custom Rule type by subclassing Rule and implementing `evaluate` with the following signature:\n",
    "\n",
    "```\n",
    "def evaluate(self, request_data: Dict[str, Any]) -> Decision:\n",
    "    # return a Decision\n",
    "```\n",
    "\n",
    "A `Decision` has two arguments, a model str and a trigger str. The trigger str explains why the decision was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3e5e9f8-6719-4735-a152-19aab6509197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomRule(Rule):\n",
    "    \"\"\"Selects a model at random.\"\"\"\n",
    "\n",
    "    def __init__(self, name:str, models: list[str]):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.models = models\n",
    "\n",
    "    def evaluate(self, _) -> Decision:\n",
    "        model = random.choice(self.models)\n",
    "        return Decision(model, \"random_selection\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "387e0025-972e-49ed-8813-bf1f55c02e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('random-router', rules=[RandomRule('rand-rule')], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rule = RandomRule(\n",
    "    name = \"rand-rule\",\n",
    "    models = [\n",
    "        \"openai/gpt-5-nano\",\n",
    "        \"qwen/qwen-turbo\",\n",
    "        \"x-ai/grok-3-mini\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"random-router\",\n",
    "    rules = [rand_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1aa4bd9-a5be-4ed4-bc04-7512a9158838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm Qwen, a large-scale language model developed by Alibaba Group. I can help with a wide range of tasks, such as answering questions, creating text, writing stories, coding, and more. I'm here to assist you in any way I can. What would you like to ask or discuss? I'm looking forward to our conversation!\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'qwen/qwen-turbo', 'original_model_field': 'qwen/qwen-turbo', 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'qwen/qwen-turbo'}]}\n",
      "---\n",
      "Sure, I'd be happy to! I'm Grok, an AI assistant created by xAI, with the goal of being super helpful, truthful, and a bit wittyâ€”like a mix of a know-it-all encyclopedia and the Hitchhiker's Guide to the Galaxy. I'm designed to answer questions, spark ideas, and tackle all sorts of topics without pulling punches, all while staying independent from any other companies' tech. What's on your mind next? ðŸ˜Š\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'x-ai/grok-3-mini', 'original_model_field': 'x-ai/grok-3-mini', 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'x-ai/grok-3-mini'}]}\n",
      "---\n",
      "Hi there! I'm Qwen, a large-scale language model developed by Alibaba Group. I can help with a wide range of tasks, such as answering questions, creating text, writing stories, coding, and more. I'm designed to be helpful, harmless, and honest. I'm always learning and improving, so I'm excited to chat with you and see what we can accomplish together! What would you like to talk about?\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'qwen/qwen-turbo', 'original_model_field': 'qwen/qwen-turbo', 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'qwen/qwen-turbo'}]}\n",
      "---\n",
      "Sure! I'm Grok, an AI assistant created by xAI to be as helpful and truthful as possible. I'm not based on any other companies' modelsâ€”instead, I'm built from the ground up with a focus on answering questions accurately, providing useful insights, and adding a dash of wit when appropriate. I'm here to chat about pretty much anything, from science and tech to everyday curiosities. What's on your mindâ€”tell me more about you, or ask me something? ðŸ˜Š\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'x-ai/grok-3-mini', 'original_model_field': 'x-ai/grok-3-mini', 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'x-ai/grok-3-mini'}]}\n",
      "---\n",
      "Iâ€™m ChatGPT, a large language model created by OpenAI. I generate text-based responses to questions and tasks, and I can help with a wide range of topics.\n",
      "\n",
      "What I can do:\n",
      "- Explain concepts, summarize articles, and tutor on topics youâ€™re learning\n",
      "- Help brainstorm ideas, draft emails, write or edit text, and create outlines\n",
      "- Assist with programming: explain code, debug, or write examples\n",
      "- Translate or adapt content to different tones or styles\n",
      "- Plan projects, study schedules, or trips, and more\n",
      "\n",
      "How I work:\n",
      "- I analyze your prompt, use relevant context from our conversation, and generate a helpful answer\n",
      "- I donâ€™t browse the web by default, and my knowledge has a cutoff (roughly up to 2023â€“2024 depending on the version)\n",
      "- I donâ€™t know personal information about you unless you share it during our chat, and I donâ€™t retain details between sessions unless memory features are enabled\n",
      "\n",
      "Limitations and tips:\n",
      "- I can be wrong or outdated; fact-check important details\n",
      "- I donâ€™t have real-time data or access to private data unless you provide it here\n",
      "- For medical, legal, or major decisions, consult a qualified professional\n",
      "- Be specific about your goal, provide context, and tell me your preferred tone or format for the best results\n",
      "\n",
      "Want to see a quick example or tell me a topic youâ€™d like help with?\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'openai/gpt-5-nano', 'original_model_field': 'openai/gpt-5-nano', 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'openai/gpt-5-nano'}]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "\n",
    "    prompt = \"Tell me something about yourself.\"\n",
    "\n",
    "    response= chat.completions.create(\n",
    "       model=\"deimos/random-router\",\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": prompt}\n",
    "       ],\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print()\n",
    "    print(response._deimos_metadata)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4501990-f1fc-421c-8de6-62196660d901",
   "metadata": {},
   "source": [
    "## Rule Chaining\n",
    "\n",
    "Rules can call other rules instead of models. For example, you might want to first determine if code is present before determining which code language is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e63a787d-e888-4b7c-94c1-842a830786f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('maybe_code_maybe_not', rules=[CodeRule('code-or-not-code', 'deimos/rules/code-lang-rule', 'openai/gpt-4o')], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_lang_rule = CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "code_or_not = CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = \"deimos/rules/code-lang-rule\",\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Router(\n",
    "    name = \"maybe_code_maybe_not\",\n",
    "    rules = [code_or_not]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3de37fef-6961-48d8-8c93-2a03737dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts.\n"
     ]
    }
   ],
   "source": [
    "not_code_prompt = \"Tell me a joke.\"\n",
    "\n",
    "not_code_response= chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": not_code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(not_code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "529fa314-94ff-4642-abd6-7f936d76f603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'maybe_code_maybe_not',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b97a810-c29c-4dc5-a340-ee41438e6b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a simple function named f that takes a parameter x and returns the square of x.\n"
     ]
    }
   ],
   "source": [
    "code_prompt = \"\"\"\n",
    "def f(x):\n",
    "    return x**2\n",
    "\"\"\"\n",
    "\n",
    "code_response = chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2fe48d8f-3fcf-4f22-a1fc-4c8b401d3851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'maybe_code_maybe_not',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'continue'},\n",
       "  {'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e77534-184b-4591-8fd6-9bd46fbd9918",
   "metadata": {},
   "source": [
    "## Rule Fallthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95dd94-3ae0-4dee-a4b7-c3bcb0af0000",
   "metadata": {},
   "source": [
    "You can also list more than one rule in the router. In this case, if the first rule does not match any defined case, the next rule will be used, and so on until a rule that returns a model is found. You can also define a default model on a router, which is used if no rule returns a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "baba73eb-a633-4fbe-86c9-3f018734745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('haiku-but-not-limericks', rules=[NaturalLanguageRule('nat-lang-rule', {'FR': 'openai/gpt-3.5-turbo', 'ES': 'openai/gpt-5-mini'}, default=None, llm_model='openai/gpt-4o-mini'), AutoTaskRule('auto-task-rule', {'writing code': 'openai/gpt-5', 'medical advice': 'openai/gpt-5-mini', 'haiku composition': 'openai/gpt-5-nano'}, default=None, llm_model='openai/gpt-5-nano')], default='openai/gpt-4o')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lang_rule = NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"FR\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "auto_task = AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"medical advice\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"haiku-but-not-limericks\",\n",
    "    rules = [nat_lang_rule, auto_task],\n",
    "    default = \"openai/gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e8e826a-56bd-417e-b78d-809231f7cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deimos, god of dread\n",
      "From war's shadow, he moves near.\n",
      "Fear trails in his wake.\n"
     ]
    }
   ],
   "source": [
    "haiku_request = \"Write me a short poem with three lines and 17 syllables on Deimos (the god, not the moon).\"\n",
    "\n",
    "haiku_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": haiku_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "18aca3ed-39b9-49ba-a65f-f4cc09c492e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'haiku-but-not-limericks',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'no_language_detected',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc9ff723-ddca-46ac-9944-0637d3dd0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coder set out on a quest,  \n",
      "To optimize code for a test,  \n",
      "But the loops nested deep,  \n",
      "Made his sanity leap,  \n",
      "Now his brainâ€™s out for garbage collect!\n"
     ]
    }
   ],
   "source": [
    "limerick_request = \"Write a funny five line poem, with AABBA rhyme scheme and a sing-songy meter, about any computer science subject.\"\n",
    "\n",
    "limerick_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": limerick_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(limerick_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e989e052-2dd9-4bc8-8e4b-e91848f37c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'haiku-but-not-limericks',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'no_language_detected',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'default',\n",
       "   'rule_name': 'default',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limerick_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989afb1-9954-433c-b1d8-e50deaba0030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4c9ed-ad16-44bf-ade2-aa553df8be63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5bfff-0d7f-4268-89b5-3626837561a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
