{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702cb18f-6032-4d03-bb3b-da8f4bdc0cf4",
   "metadata": {},
   "source": [
    "# Deimos Router\n",
    "\n",
    "Deimos is the smallest, ugliest moon of Mars.\n",
    "\n",
    "Deimos is also the smallest, dumbest way to do routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dade040-5d4d-4d1b-a800-091973ab48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deimos_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f036e4f9-3061-4fb8-a31b-417931dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deimos_router import Router, register_router, chat\n",
    "from deimos_router.rules import TaskRule, AutoTaskRule, CodeRule, CodeLanguageRule, NaturalLanguageRule, MessageLengthRule, ConversationContextRule, Rule, Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7434f-ba3e-4154-807a-1cbc293e0328",
   "metadata": {},
   "source": [
    "## Basic Usage - Task Based Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7122b-ca0c-4d4a-baf0-fa395bbdf45f",
   "metadata": {},
   "source": [
    "A Router uses one or more Rules to select a model. The simplest Rule is TaskRule, which maps task names to models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c16b786-c72b-4aea-b56b-1f0168ccffb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaskRule('task-based-routing', {'coding': 'openai/gpt-5', 'creative': 'openai/gpt-4o', 'simple': 'openai/gpt-5-nano'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskRule(\n",
    "    name=\"task-based-routing\",\n",
    "    triggers={\n",
    "       'coding': 'openai/gpt-5',\n",
    "       'creative': 'openai/gpt-4o',\n",
    "       'simple': 'openai/gpt-5-nano'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafdefd0-603d-4aac-b5fc-7d437a7cbc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('my-first-router', rules=['deimos/rules/task-based-routing'], default='openai/gpt-4o-mini')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "   name=\"my-first-router\",\n",
    "   rules=[\"deimos/rules/task-based-routing\"],\n",
    "   default=\"openai/gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace38270-a991-4ff6-a0f4-d797a20d7df4",
   "metadata": {},
   "source": [
    "To use a Router, make a call to `chat.completions.create`, as if it were a call to OpenAI's SDK, and specify the router as the model.\n",
    "\n",
    "For simple task-based routing, include the task name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e28bc9-23b5-4d1d-9eee-8faf8c6aedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number with 0-indexing:\n",
      "      F(0) = 0, F(1) = 1, F(2) = 1, ...\n",
      "    Uses fast doubling (O(log n) time).\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int) or n < 0:\n",
      "        raise ValueError(\"n must be a non-negative integer\")\n",
      "\n",
      "    def _fib(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return (0, 1)\n",
      "        a, b = _fib(k >> 1)\n",
      "        c = a * (2 * b - a)\n",
      "        d = a * a + b * b\n",
      "        if k & 1:\n",
      "            return (d, c + d)\n",
      "        else:\n",
      "            return (c, d)\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response = chat.completions.create(\n",
    "   model=\"deimos/my-first-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b713-71df-4584-b305-4115e89b4181",
   "metadata": {},
   "source": [
    "Details about the routing decision can be found in the response at `._deimos_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ca7ab1-deec-43fb-a856-675687acebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'my-first-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'TaskRule',\n",
       "   'rule_name': 'task-based-routing',\n",
       "   'rule_trigger': 'coding',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4453-abc1-4850-86e7-56d699d65cbc",
   "metadata": {},
   "source": [
    "## AutoTask Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6b54-afde-4e92-918b-544bbc535300",
   "metadata": {},
   "source": [
    "An `AutoTaskRule` is created in the same way as a `TaskRule`, but the task is determined by a call to a small language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a96242-92fa-495c-a269-e9a8163ebae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoTaskRule('auto-task-rule', {'creative writing': 'openai/gpt-4o', 'writing code': 'openai/gpt-5', 'informational': 'openai/gpt-5-mini', 'haiku composition': 'openai/gpt-5-nano'}, default=None, llm_model='openai/gpt-5-nano')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"creative writing\" : \"openai/gpt-4o\",\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"informational\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e90e8f-19cc-4849-9336-683fbe65443d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('auto-router', rules=['deimos/rules/auto-task-rule'], default='openai/gpt-4o-mini')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "    name = \"auto-router\",\n",
    "    rules = [\"deimos/rules/auto-task-rule\"],\n",
    "    default=\"openai/gpt-4o-mini\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b239d0-38f0-4bf3-a404-2020d8780206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number using fast doubling.\n",
      "    0-indexed: fib(0)=0, fib(1)=1, fib(2)=1, ...\n",
      "    Raises ValueError for negative n.\n",
      "    Runs in O(log n) time.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be non-negative\")\n",
      "\n",
      "    def _fib(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return (0, 1)\n",
      "        a, b = _fib(k >> 1)  # a = F(k), b = F(k+1)\n",
      "        c = a * ((b << 1) - a)  # F(2k)\n",
      "        d = a * a + b * b       # F(2k+1)\n",
      "        if k & 1:\n",
      "            return (d, c + d)\n",
      "        else:\n",
      "            return (c, d)\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response1 = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3492f8f-86a9-4791-a306-27f5d5f02d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'writing code',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "263d7d03-50b7-4f2f-b692-727e5ed4085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "砂の星\n",
      "風が火星を\n",
      "揺らす砂\n"
     ]
    }
   ],
   "source": [
    "haiku = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a short japanese poem about mars, and follow the syllable count 5, 7, 5\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d3f649b-aacb-4dec-9a74-e8ca115cb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde49483-d23d-4774-8688-e177ccec95a3",
   "metadata": {},
   "source": [
    "## Code / Not code Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e4391-887e-4164-9145-2cf91a5d7cd5",
   "metadata": {},
   "source": [
    "The `CodeRule` is a very simple rule that determines whether a prompt contains code and routes based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ff4960c-efc8-41e0-a822-61e002e230a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('code-nocode-router', rules=['deimos/rules/code-or-not-code'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = \"openai/gpt-5\",\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-nocode-router\",\n",
    "    rules = [\"deimos/rules/code-or-not-code\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e066e5-93ca-4b93-a0cd-2d46ee0c9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You’re using exponentiation (**) instead of multiplication. Use the * operator.\n",
      "\n",
      "Corrected code:\n",
      "```\n",
      "def multiply(x, y):\n",
      "    return x * y\n",
      "```\n",
      "\n",
      "Example:\n",
      "- multiply(3, 4) -> 12\n",
      "- multiply(2, 5) -> 10\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Debug this:\n",
    "```\n",
    "def multiply(x, y):\n",
    "    return x**y\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_1 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa69ce97-da19-4b47-80c0-23670255fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a63dcc2-a479-42f1-9504-5cb09256c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars has two small moons, Phobos and Deimos. Of the two, Phobos is generally considered the smaller and less aesthetically appealing. Phobos is heavily cratered, irregularly shaped, and has a very rugged surface, which contributes to its \"ugly\" appearance compared to other moons in the solar system. It is the larger of the two Martian moons but still quite small at about 22.4 kilometers in diameter. Its close orbit around Mars and its dark, dusty surface add to its unique and rather stark appearance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the smallest, ugliest moon of Mars?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_2 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471b406c-8d5a-4b1f-be94-60a4d0cb43db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_2._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce564b-3e21-4037-bf1d-ef00974c9097",
   "metadata": {},
   "source": [
    "## Code Language Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d74a7c-8067-4299-af77-878bedc65931",
   "metadata": {},
   "source": [
    "To route based on programming language, use a CodeLanguage rule.\n",
    "\n",
    "This rule uses regex to classify among several popular languages, and then falls back to a small language model call to determine language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3137e1d6-9037-4e35-96f4-19937eaa54ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('code-lang-router', rules=['deimos/rules/code-lang-rule'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-lang-router\",\n",
    "    rules = [\"deimos/rules/code-lang-rule\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c4b84c7-9c6f-457f-bc9a-f145c12e5c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function calculates the nth Fibonacci number using the iterative method where the Fibonacci numbers are generated by repeatedly adding the two previous numbers in the sequence. It uses bitwise operations to efficiently calculate the Fibonacci number at position n.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "179ee0db-bb65-47ed-9062-7cee30f4eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08b1e0a6-21a2-4655-9119-baaf0f8630c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a SQL query. It returns every column for every row in the table named people where the column name equals \"john\".\n",
      "\n",
      "Line-by-line:\n",
      "- SELECT * — select all columns.\n",
      "- FROM people — from the table called people.\n",
      "- WHERE name = \"john\" — filter rows to those whose name equals \"john\".\n",
      "\n",
      "Notes and gotchas:\n",
      "- It produces a result set (zero or more rows); it does not modify the database.\n",
      "- Standard SQL uses single quotes for string literals: WHERE name = 'john'. In some databases double quotes denote identifiers, and in others (e.g. default MySQL) double quotes may act like single quotes; behavior depends on the DBMS.\n",
      "- Case-sensitivity depends on the column collation. For a case-insensitive match use e.g. WHERE LOWER(name) = 'john' or (in PostgreSQL) WHERE name ILIKE 'john'.\n",
      "- For partial matches use LIKE (e.g. WHERE name LIKE '%john%').\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does code do?\n",
    "```\n",
    "SELECT *\n",
    "FROM people\n",
    "WHERE name = \"john\"\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b7c6a5-c8fb-4819-9c23-1099a64a8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'sql',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994841eb-e468-4447-ad97-de65062189d6",
   "metadata": {},
   "source": [
    "## NaturalLanguageRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f11a8f-8462-4f29-aa3b-55c72d808ac8",
   "metadata": {},
   "source": [
    "To route based on the language of the request (English, French, Spanish, etc), use a NaturalLanguageRule. This calls a small language model to detect the language. Specify language:model mapping using the two-letter ISO language code (`EN`, `FR`, `ES`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75580c2b-bd8d-49c2-a8c9-c1929bf420f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('nat-lang-router', rules=['deimos/rules/nat-lang-rule'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"EN\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"nat-lang-router\",\n",
    "    rules = [\"deimos/rules/nat-lang-rule\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61d51600-d9a8-4fae-91a3-aafe1d629abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the grammar teacher go to jail? \n",
      "Because she kept committing homonyms!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me a joke about language.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65dd159d-c716-450a-bc05-125dc919d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'EN',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4baa8df-1f1f-42a3-8dd9-082d57759356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un clásico corto:\n",
      "\n",
      "Un lingüista entra en un bar. El camarero le pregunta: \"¿Qué quiere tomar?\" El lingüista responde: \"Depende del contexto\".\n",
      "\n",
      "Y otro rápido:\n",
      "\n",
      "—¿Por qué los sinónimos no pelean?  \n",
      "—Porque siempre están de acuerdo en algo.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Cuéntame un chiste sobre el lenguaje.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8880aeb8-ae95-4a00-b1cc-a5e0ddb972d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'ES',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faca0dd-9586-4f17-9fcd-6b54f6c3b283",
   "metadata": {},
   "source": [
    "## MessageLengthRule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7ccc5-e025-461f-af9d-ec0e0f52ee1d",
   "metadata": {},
   "source": [
    "The MessageLengthRule selects one of three models based on length (in tokens) of the user message. \n",
    "\n",
    "- short: below the `short_threshold`\n",
    "- medium: between the `short_threshold` and the `long_threshold`\n",
    "- long: above the `long_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a468af6e-b0db-4fb2-8596-50c0ef5bcd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router('length-router', rules=['deimos/rules/msg-len'], default='gpt-3.5-turbo')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MessageLengthRule(\n",
    "    name = \"msg-len\",\n",
    "    short_threshold = 50,\n",
    "    long_threshold = 200,\n",
    "    short_model = \"openai/gpt-5-nano\",\n",
    "    medium_model = \"openai/gpt-5-mini\",\n",
    "    long_model = \"openai/gpt-5\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"length-router\",\n",
    "    rules = [\"deimos/rules/msg-len\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "359b0d50-2e00-419f-93e0-5f0890d99bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars is generally described as reddish-orange, often called the Red Planet. This coloration comes from iron oxide (rust) on its surface and dust in the atmosphere. In some views it can look more orange-red, and its polar caps appear white.\n"
     ]
    }
   ],
   "source": [
    "short_prompt = \"What color is Mars?\"\n",
    "\n",
    "short_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": short_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(short_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0afba91b-d472-4e5b-920f-8bbe2a708a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'msg-len',\n",
       "   'rule_trigger': 'short_message_5_tokens',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4de8ef63-5fe4-4af1-8017-9347e422611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: The TokenTales SkyRail — “Stories that Fly”\n",
      "\n",
      "Concept in one line\n",
      "An aerial, slow-moving gondola ride that combines a cable-suspended scenic tram, a choose‑your‑own‑adventure storyteller’s toolkit (physical tokens), large-scale puppet theater and adaptive live music — so each trip becomes a unique, communal story told in motion.\n",
      "\n",
      "How it looks\n",
      "- The line and station feel like a giant open storybook: paper‑textured canopies, warm lantern light, and carved wooden shelves with glowing token bins.\n",
      "- Gondola pods are cradle‑like “origami boats” of painted timber and glass (4–6 passengers each), suspended from a graceful cable that winds above a theatrical landscape of miniature worlds.\n",
      "- Below and alongside the line are modular stage-sets — forests with mechanical trees, an “ocean” of reflective ribbons, clockwork cities, a mountain plateau with puppet giants, and hidden nooks for actors and animatronics to peek out.\n",
      "- Lighting rigs, scent emitters, subtle wind and mist effects, projection mapping and roaming drones integrate with hand-operated puppetry on the ground to create layered scenes.\n",
      "\n",
      "How it works — step by step\n",
      "1. Choose your tokens: before boarding, each guest picks 3–5 wooden tokens from the Story Shelf. Each token is an archetype or element (e.g., Hero, Trickster, Moon, Forbidden Door, Compass, Songbird, Storm, Map, Mirror, Timepiece). Tokens are tactile, painted and slightly different sizes so kids can read them by shape alone.\n",
      "2. Register your sequence: slide your tokens into the pod’s console in the order you want. The pod’s screen shows a playful “story score” that interprets token order into themes (bravery, mischief, memory, etc.).\n",
      "3. Lift‑off and weave: as the pod glides along the cable, the SkyRail’s show engine (a narrative director computer + live stage team) translates each token sequence into a tailored run of scenes. Animatronics rearrange small set pieces, puppeteers bring characters to life, projections change the sky, scent cues and wind mists match the mood, and a live or AI-assisted orchestra (on-site musicians plus adaptive audio) composes an evolving soundtrack to match.\n",
      "4. Real-time audience control: the tokens in every pod are networked to the show system. When multiple pods choose aligned elements (e.g., many pods pick “Storm”), the whole route may darken and the music swells. If a single pod opts for “Secret Garden,” a hidden corner of the set opens only for that pod to see — a tiny puppet reveals a token-sized keepsake.\n",
      "5. Interactions on the ground: puppeteers and actors in costume occasionally interact with the pods — waving, passing a rope ladder for a playful “rescue” scene, or slotting a dramatic flourish in response to a child’s shout. Large bunraku-style puppets and kinetic sculptures perform sweeping motions visible from above.\n",
      "6. The finale: the last token triggers a “bookbinding” finale — projection paints a floating book page visible from the pod that shows snapshots from the ride’s story. When you disembark, a small printed story scroll is waiting (or a QR code to download a personalized animated short and the soundtrack), summarizing the tale you created.\n",
      "\n",
      "What makes it magical and fun\n",
      "- Tactile storytelling: choosing physical tokens engages children and adults alike; the cause‑and‑effect of slotting a token and then seeing it change the world around you feels like real magic.\n",
      "- Collective play: the ride is both personal and social. Your pod’s choices matter, but when multiple riders sync up, the world responds in bigger ways. Friends and strangers can co‑author a bigger story on the fly.\n",
      "- Multi‑sensory immersion: sight, sound, scent, touch and gentle motion combine to form a vividly memorable experience that’s entirely non‑thrill (suitable for all ages) but endlessly replayable.\n",
      "- Live theater + adaptive tech: the blend of live puppetry and actors with AI-assisted music and projection means no two rides are precisely the same; performers can improvise with guests, giving a warm human heartbeat to the tech.\n",
      "- Keepsakes and replayability: the printed scroll/QR download lets families relive the adventure — and try different token combos next time to discover new twists and endings.\n",
      "\n",
      "Sample ride moments\n",
      "- Insert “Hero, Map, Night” → Your pod watches a silhouetted hero chase fireflies through a moonlit clock-town; a gentle breeze brings the smell of pine; a puppet owl drops a tiny lantern onto the pod railing.\n",
      "- Insert “Trickster, Mirror, Storm” → Paper boats appear on a mirrored pool below, reflections misbehave, and the soundtrack hops into playful syncopation while a puppet fox rearranges the scene.\n",
      "- Many pods choose “Songbird” at once → The whole route bursts into birdlike harmonies; projectors paint lyric ribbons across the sky and a chorus of hidden pipes answers.\n",
      "\n",
      "Accessibility and safety\n",
      "- Slow-moving, accessible gondolas with space for wheelchairs.\n",
      "- Visual and audio cues are complemented by tactile tokens and haptic feedback in the seats.\n",
      "- All effects are non‑invasive, adjustable for sensory-sensitive guests.\n",
      "\n",
      "Why DreamTopia needs it\n",
      "TokenTales SkyRail is the park’s manifesto attraction: it celebrates imagination as a communal craft, blends tradition (puppetry, books) with modern storytelling tech, and gives guests agency — not just to experience a ride, but to co-create a small, ephemeral world.\n",
      "\n",
      "Poster tagline/slogan\n",
      "TokenTales SkyRail — Catch a Story. Let It Carry You.\n"
     ]
    }
   ],
   "source": [
    "medium_prompt = \"Imagine you’ve just been hired as the Chief Imagination Officer for a brand-new amusement park called DreamTopia. Your first assignment is to design the park’s most unusual and delightful attraction, something that no other park has ever seen before. It should combine at least two completely different ideas (for example: a roller coaster made of books, or a water slide that doubles as a musical instrument). Please describe the attraction in detail: how it looks, how it works, and what makes it magical or fun. End with a short tagline or slogan that could go on the park’s posters.\"\n",
    "\n",
    "medium_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": medium_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(medium_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42ed9e93-b099-4325-aa43-199fd74d1687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'msg-len',\n",
       "   'rule_trigger': 'medium_message_119_tokens',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed112c-6ab6-4a3e-afec-5b225ed79150",
   "metadata": {},
   "source": [
    "## ConversationContextRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353b465-be4a-4e13-902b-93483ce84399",
   "metadata": {},
   "source": [
    "ConversationContextRule selects model based on the number of back-and-forth messages in a conversation, classifying a conversation as new, developing, or deep.\n",
    "\n",
    "- new conversation: less than `new_threshold` number of messages\n",
    "- developing conversation: between `new_threshold` and `deep_theshold` number of messages\n",
    "- deep conversation: longer than `deep_threshold` number of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c444b-d09f-4cb9-83a5-438a6c13c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_rule = ConversationContextRule(\n",
    "    name = \"conv-context-rule\",\n",
    "    new_threshold = 3,\n",
    "    deep_threshold = 10,\n",
    "    new_model = \"openai/gpt-5-nano\",\n",
    "    developing_model = \"openai/gpt-4o-mini\",\n",
    "    deep_model = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"context-router\",\n",
    "    rules = [context_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3221777a-4ce9-48e9-9120-09edbc5d30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Tell me the funnest fact about Deimos (the moon, not the god).\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(new_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9292e1b-2ee0-4f42-ba31-cf0d7c805229",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022cbed9-2c83-4954-bd0c-57d6826cd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hi there! Can you help me come up with a fun name for a coffee shop?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Of course! How about 'Bean There, Done That'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Haha, that’s clever. Can you give me a couple more options?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Sure! Some other ideas: 'Daily Grind Café' and 'Perk Up Coffeehouse.'\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Nice! I like 'Perk Up.' Can you suggest a tagline to go with it?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"How about: 'Perk Up — Where Every Cup Sparks Joy'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Perfect, that’s exactly what I was looking for. Thanks!\"\n",
    "    }\n",
    "  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b257399-d65c-4139-a1f7-f4368210850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "developing_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=conversation,\n",
    ")\n",
    "\n",
    "print(developing_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2655be2-7a4d-4c51-a3bd-124eb2076081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "developing_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544687a-ded6-4384-b7cf-aa4f8bfffd8b",
   "metadata": {},
   "source": [
    "## Custom Rule Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a7a8d-dc7c-4695-94e8-65b40e008bfe",
   "metadata": {},
   "source": [
    "You can create your own custom Rule type by subclassing Rule and implementing `evaluate` with the following signature:\n",
    "\n",
    "```\n",
    "def evaluate(self, request_data: Dict[str, Any]) -> Decision:\n",
    "    # return a Decision\n",
    "```\n",
    "\n",
    "A `Decision` has two arguments, a model str and a trigger str. The trigger str explains why the decision was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5e9f8-6719-4735-a152-19aab6509197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomRule(Rule):\n",
    "    \"\"\"Selects a model at random.\"\"\"\n",
    "\n",
    "    def __init__(self, name:str, models: list[str]):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.models = models\n",
    "\n",
    "    def evaluate(self, _) -> Decision:\n",
    "        model = random.choice(self.models)\n",
    "        return Decision(model, \"random_selection\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0025-972e-49ed-8813-bf1f55c02e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_rule = RandomRule(\n",
    "    name = \"rand-rule\",\n",
    "    models = [\n",
    "        \"openai/gpt-5-nano\",\n",
    "        \"qwen/qwen-turbo\",\n",
    "        \"x-ai/grok-3-mini\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"random-router\",\n",
    "    rules = [rand_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa4bd9-a5be-4ed4-bc04-7512a9158838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "\n",
    "    prompt = \"Tell me something about yourself.\"\n",
    "\n",
    "    response= chat.completions.create(\n",
    "       model=\"deimos/random-router\",\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": prompt}\n",
    "       ],\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print()\n",
    "    print(response._deimos_metadata)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4501990-f1fc-421c-8de6-62196660d901",
   "metadata": {},
   "source": [
    "## Rule Chaining\n",
    "\n",
    "Rules can call other rules instead of models. For example, you might want to first determine if code is present before determining which code language is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a787d-e888-4b7c-94c1-842a830786f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_lang_rule = CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "code_or_not = CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = code_lang_rule,\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Router(\n",
    "    name = \"maybe_code_maybe_not\",\n",
    "    rules = [code_or_not]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de37fef-6961-48d8-8c93-2a03737dfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_code_prompt = \"Tell me a joke.\"\n",
    "\n",
    "not_code_response= chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": not_code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(not_code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529fa314-94ff-4642-abd6-7f936d76f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11851ed-48b4-4d45-8552-71bc0b422f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "code_response = chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe48d8f-3fcf-4f22-a1fc-4c8b401d3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e77534-184b-4591-8fd6-9bd46fbd9918",
   "metadata": {},
   "source": [
    "## Rule Fallthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95dd94-3ae0-4dee-a4b7-c3bcb0af0000",
   "metadata": {},
   "source": [
    "You can also list more than one rule in the router. In this case, if the first rule does not match any defined case, the next rule will be used, and so on until a rule that returns a model is found. You can also define a default model on a router, which is used if no rule returns a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baba73eb-a633-4fbe-86c9-3f018734745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_lang_rule = NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"FR\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "auto_task = AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"medical advice\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"haiku-but-not-limericks\",\n",
    "    rules = [nat_lang_rule, auto_task],\n",
    "    default = \"openai/gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8e826a-56bd-417e-b78d-809231f7cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_request = \"Write me a short poem with three lines and 17 syllables on Deimos (the god, not the moon).\"\n",
    "\n",
    "haiku_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": haiku_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aca3ed-39b9-49ba-a65f-f4cc09c492e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ff723-ddca-46ac-9944-0637d3dd0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "limerick_request = \"Write a funny five line poem, with AABBA rhyme scheme and a sing-songy meter, about any computer science subject.\"\n",
    "\n",
    "limerick_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": limerick_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(limerick_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989e052-2dd9-4bc8-8e4b-e91848f37c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "limerick_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989afb1-9954-433c-b1d8-e50deaba0030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
