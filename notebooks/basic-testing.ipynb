{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702cb18f-6032-4d03-bb3b-da8f4bdc0cf4",
   "metadata": {},
   "source": [
    "# Deimos Router\n",
    "\n",
    "Deimos is the smallest, ugliest moon of Mars.\n",
    "\n",
    "Deimos is also the smallest, dumbest way to do routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dade040-5d4d-4d1b-a800-091973ab48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deimos_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f036e4f9-3061-4fb8-a31b-417931dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deimos_router import Router, register_router, chat\n",
    "from deimos_router.rules import TaskRule, AutoTaskRule, CodeRule, CodeLanguageRule, NaturalLanguageRule, MessageLengthRule, ConversationContextRule, Rule, Decision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7434f-ba3e-4154-807a-1cbc293e0328",
   "metadata": {},
   "source": [
    "## Basic Usage - Task Based Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7122b-ca0c-4d4a-baf0-fa395bbdf45f",
   "metadata": {},
   "source": [
    "A Router uses one or more Rules to select a model. The simplest Rule is TaskRule, which maps task names to models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafdefd0-603d-4aac-b5fc-7d437a7cbc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='my-first-router', models=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "   name=\"my-first-router\",\n",
    "   rules=[\n",
    "       TaskRule(\n",
    "           name=\"task-based-routing\",\n",
    "           triggers={\n",
    "               'coding': 'openai/gpt-5',\n",
    "               'creative': 'openai/gpt-4o',\n",
    "               'simple': 'openai/gpt-5-nano'\n",
    "           }\n",
    "       )\n",
    "   ],\n",
    "   default=\"openai/gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace38270-a991-4ff6-a0f4-d797a20d7df4",
   "metadata": {},
   "source": [
    "To use a Router, make a call to `chat.completions.create`, as if it were a call to OpenAI's SDK, and specify the router as the model.\n",
    "\n",
    "For simple task-based routing, include the task name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e28bc9-23b5-4d1d-9eee-8faf8c6aedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fibonacci(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number with F(0)=0 and F(1)=1.\n",
      "    Uses fast doubling (O(log n)). n must be a non-negative integer.\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be non-negative\")\n",
      "\n",
      "    def fib_pair(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return (0, 1)\n",
      "        a, b = fib_pair(k // 2)\n",
      "        c = a * (2 * b - a)      # F(2m)\n",
      "        d = a * a + b * b        # F(2m+1)\n",
      "        return (c, d) if k % 2 == 0 else (d, c + d)\n",
      "\n",
      "    return fib_pair(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response = chat.completions.create(\n",
    "   model=\"deimos/my-first-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b713-71df-4584-b305-4115e89b4181",
   "metadata": {},
   "source": [
    "Details about the routing decision can be found in the response at `._deimos_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ca7ab1-deec-43fb-a856-675687acebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'my-first-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'TaskRule',\n",
       "   'rule_name': 'task-based-routing',\n",
       "   'rule_trigger': 'coding',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4453-abc1-4850-86e7-56d699d65cbc",
   "metadata": {},
   "source": [
    "## AutoTask Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6b54-afde-4e92-918b-544bbc535300",
   "metadata": {},
   "source": [
    "An `AutoTaskRule` is created in the same way as a `TaskRule`, but the task is determined by a call to a small language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a96242-92fa-495c-a269-e9a8163ebae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_task = AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"creative writing\" : \"openai/gpt-4o\",\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"informational\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e90e8f-19cc-4849-9336-683fbe65443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_router = Router(\n",
    "    name = \"auto-router\",\n",
    "    rules = [auto_task],\n",
    "    default=\"openai/gpt-4o-mini\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b239d0-38f0-4bf3-a404-2020d8780206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number (0-indexed: F(0)=0, F(1)=1).\n",
      "    Uses fast doubling for O(log n) time.\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"n must be an int\")\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be non-negative\")\n",
      "\n",
      "    def _fib(k: int) -> tuple[int, int]:\n",
      "        if k == 0:\n",
      "            return 0, 1\n",
      "        a, b = _fib(k // 2)\n",
      "        c = a * (2 * b - a)\n",
      "        d = a * a + b * b\n",
      "        if k % 2 == 0:\n",
      "            return c, d\n",
      "        else:\n",
      "            return d, c + d\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response1 = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3492f8f-86a9-4791-a306-27f5d5f02d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'writing code',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263d7d03-50b7-4f2f-b692-727e5ed4085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚ã‹ã„ã»ã—\n",
      "ç ‚ã‚’å¹ãé¢¨\n",
      "ã‚ã‹ã„ã‚†ã‚\n"
     ]
    }
   ],
   "source": [
    "haiku = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a short japanese poem about mars, and follow the syllable count 5, 7, 5\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3f649b-aacb-4dec-9a74-e8ca115cb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde49483-d23d-4774-8688-e177ccec95a3",
   "metadata": {},
   "source": [
    "## Code / Not code Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e4391-887e-4164-9145-2cf91a5d7cd5",
   "metadata": {},
   "source": [
    "The `CodeRule` is a very simple rule that determines whether a prompt contains code and routes based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff4960c-efc8-41e0-a822-61e002e230a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_or_not = CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = \"openai/gpt-5\",\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "code_no_code_router = Router(\n",
    "    name = \"code-nocode-router\",\n",
    "    rules = [code_or_not]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e066e5-93ca-4b93-a0cd-2d46ee0c9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You used exponentiation (**) instead of multiplication. Hereâ€™s the fix:\n",
      "\n",
      "```python\n",
      "def multiply(x, y):\n",
      "    return x * y\n",
      "```\n",
      "\n",
      "Quick check:\n",
      "- multiply(2, 3) -> 6\n",
      "- multiply(-4, 5) -> -20\n",
      "- multiply(3.5, 2) -> 7.0\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Debug this:\n",
    "```\n",
    "def multiply(x, y):\n",
    "    return x**y\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_1 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa69ce97-da19-4b47-80c0-23670255fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a63dcc2-a479-42f1-9504-5cb09256c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars has two small moons, Phobos and Deimos. Of the two, Phobos is considered both the smaller and the more irregularly shaped, often described as the less aesthetically pleasing or \"uglier\" moon. Phobos is heavily cratered with a somewhat lumpy appearance. It is also the closer of the two moons to Mars and is gradually spiraling inward, which will eventually lead to it either crashing into Mars or breaking apart.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the smallest, ugliest moon of Mars?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_2 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471b406c-8d5a-4b1f-be94-60a4d0cb43db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_2._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce564b-3e21-4037-bf1d-ef00974c9097",
   "metadata": {},
   "source": [
    "## Code Language Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d74a7c-8067-4299-af77-878bedc65931",
   "metadata": {},
   "source": [
    "To route based on programming language, use a CodeLanguage rule.\n",
    "\n",
    "This rule uses regex to classify among several popular languages, and then falls back to a small language model call to determine language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3137e1d6-9037-4e35-96f4-19937eaa54ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='code-lang-router', models=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_lang_rule = CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-lang-router\",\n",
    "    rules = [code_lang_rule]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4b84c7-9c6f-457f-bc9a-f145c12e5c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function calculates the nth Fibonacci number iteratively using the binary representation of the input number `n`. It computes Fibonacci numbers based on the properties of the Fibonacci sequence and the binary representation of the input number to optimize the calculation process.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "179ee0db-bb65-47ed-9062-7cee30f4eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b1e0a6-21a2-4655-9119-baaf0f8630c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an SQL query that returns all rows from the table named \"people\" where the name column equals \"john\".\n",
      "\n",
      "Breakdown:\n",
      "- SELECT * â€” return all columns.\n",
      "- FROM people â€” from the table named people.\n",
      "- WHERE name = \"john\" â€” only include rows whose name equals john.\n",
      "\n",
      "Notes and caveats:\n",
      "- Standard SQL uses single quotes for string literals: WHERE name = 'john'. Some databases (e.g. MySQL with certain modes) accept double quotes for strings, while others (e.g. PostgreSQL) treat double quotes as identifiers.\n",
      "- Comparison case-sensitivity depends on the database collation. To match regardless of case you can use LOWER(name) = 'john' or ILIKE 'john' (Postgres).\n",
      "- For safety when plugging user input into this query, use parameterized queries/prepared statements to avoid SQL injection.\n",
      "- If there is an index on name, the filter can be faster.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does code do?\n",
    "```\n",
    "SELECT *\n",
    "FROM people\n",
    "WHERE name = \"john\"\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7b7c6a5-c8fb-4819-9c23-1099a64a8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'sql',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994841eb-e468-4447-ad97-de65062189d6",
   "metadata": {},
   "source": [
    "## NaturalLanguageRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f11a8f-8462-4f29-aa3b-55c72d808ac8",
   "metadata": {},
   "source": [
    "To route based on the language of the request (English, French, Spanish, etc), use a NaturalLanguageRule. This calls a small language model to detect the language. Specify language:model mapping using the two-letter ISO language code (`EN`, `FR`, `ES`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75580c2b-bd8d-49c2-a8c9-c1929bf420f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='nat-lang-router', models=[])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lang_rule = NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"EN\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"nat-lang-router\",\n",
    "    rules = [nat_lang_rule]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61d51600-d9a8-4fae-91a3-aafe1d629abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the grammar teacher go to jail? \n",
      "\n",
      "For excessive use of sentences!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me a joke about language.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65dd159d-c716-450a-bc05-125dc919d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'EN',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4baa8df-1f1f-42a3-8dd9-082d57759356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿Sabes por quÃ© el verbo fue al psicÃ³logo?\n",
      "â€”Porque no podÃ­a conjugar sus sentimientos. \n",
      "\n",
      "Â¿Quieres otro chiste lingÃ¼Ã­stico?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "CuÃ©ntame un chiste sobre el lenguaje.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8880aeb8-ae95-4a00-b1cc-a5e0ddb972d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'ES',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faca0dd-9586-4f17-9fcd-6b54f6c3b283",
   "metadata": {},
   "source": [
    "## MessageLengthRule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7ccc5-e025-461f-af9d-ec0e0f52ee1d",
   "metadata": {},
   "source": [
    "The MessageLengthRule selects one of three models based on length (in tokens) of the user message. \n",
    "\n",
    "- short: below the `short_threshold`\n",
    "- medium: between the `short_threshold` and the `long_threshold`\n",
    "- long: above the `long_threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a468af6e-b0db-4fb2-8596-50c0ef5bcd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='length-router', models=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_rule = MessageLengthRule(\n",
    "    name = \"len_rule\",\n",
    "    short_threshold = 50,\n",
    "    long_threshold = 200,\n",
    "    short_model = \"openai/gpt-5-nano\",\n",
    "    medium_model = \"openai/gpt-5-mini\",\n",
    "    long_model = \"openai/gpt-5\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"length-router\",\n",
    "    rules = [len_rule],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359b0d50-2e00-419f-93e0-5f0890d99bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars is typically described as red or reddish-orange. This color comes from iron oxide (rust) dust on its surface and in its atmosphere. Its appearance can vary with lighting and the season, but the hallmark is the reddish hue.\n"
     ]
    }
   ],
   "source": [
    "short_prompt = \"What color is Mars?\"\n",
    "\n",
    "short_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": short_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(short_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afba91b-d472-4e5b-920f-8bbe2a708a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'len_rule',\n",
       "   'rule_trigger': 'short_message_5_tokens',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de8ef63-5fe4-4af1-8017-9347e422611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Dreamloom â€” The Coaster That Weaves Your Story\n",
      "\n",
      "Concept in one line\n",
      "A family-friendly roller-coaster crossed with a giant kinetic loom and an interactive composing studio: every ride lets guests literally add threads, music, and motifs to a communal tapestry that grows and plays the dayâ€™s unique song.\n",
      "\n",
      "How it looks\n",
      "- Exterior: a low, graceful building shaped like an oversized shuttle loom â€” curved wooden ribs, giant bobbins that turn, and glowing fiber-optic â€œthreadsâ€ stretching up the facade. At night the strands pulse like constellations.\n",
      "- Interior: the track loops around a cathedral-scale vertical loom called the Loom of Lumin (a 40â€“60 ft wall of warp threads). Suspended balconies and catwalks hold spindles, gears, and artisansâ€™ lamps. Projection-mapped murals shift between four themed â€œchaptersâ€ (Forest, Ocean, Sky, City) around the loom.\n",
      "- Cars: the coaster cars are shuttle-shaped benches with a tactile â€œSpindle Consoleâ€ in front of each rider â€” a small, kid-friendly panel with color spindles, pattern dials, and a musical ribbon pad. They look like mini hand-looms combined with train seating; comfy harnesses, room for families and wheelchairs.\n",
      "\n",
      "How it works â€” the guest experience (step-by-step)\n",
      "1. Pre-ride choice: Guests enter the Weaverâ€™s Nook where they tap a wristband to pick 1â€“3 â€œthreadsâ€ â€” colors, textures, and a musical motif (pluck, bell, drum, hum). Short prompts (mood/word choices like â€œbrave,â€ â€œmischief,â€ â€œrainâ€) give the system a storytelling seed.\n",
      "2. Board and contribute: In the car each rider uses the Spindle Console to tweak their thread (brightness, pattern repeats) and assign a note or rhythm. The console records your RFID tag, color choices and musical snippet.\n",
      "3. The ride: As the coaster glides through chapters, the Loom of Luminâ€™s robotic shuttles and weaving arms take each carâ€™s contributions and weave them into the tapestry in real time. Projection mapping turns newly woven threads into animated scenes that look like your colors are sprouting fauna, turning into waves, or forming cityscapes. Each thread triggers a live sound element; as threads interlace the parkâ€™s audio system plays the emergent composition â€” a layered â€œweave-symphonyâ€ made from ridersâ€™ chosen motifs.\n",
      "4. Shared reveal: Mid-ride, a short â€œweave sequenceâ€ slows the cars under a domed chamber where the loom reveals the latest vertical band of tapestry, lit and accompanied by the melody your ride helped create. Wind hoses, scent puffs (lavender, ocean mist, pine, warm bread) and gentle motion effects make the scene immersive.\n",
      "5. Finish: The coaster returns to the Loom Plaza where the new section of tapestry has been mounted. A digital kiosk shows a high-resolution â€œsliceâ€ representing your contributions, and the loom stitches a tiny embroidered icon of your wristband ID into the fabric as a permanent signature of your visit.\n",
      "\n",
      "What makes it magical and fun\n",
      "- Co-creation: Guests donâ€™t just ride; they collaborate across generations. The tapestry is literally built by park visitors every day â€” a living artwork that records the parkâ€™s collective imagination.\n",
      "- Multi-sensory storytelling: Color, texture, scent, wind, and music all respond to guestsâ€™ tiny choices, so each ride feels like a new, personal story unfolding in public.\n",
      "- Visible impact: You can point to the loom and say, â€œI helped make that blue wave,â€ or come back later to see how your stitch has changed in context with thousands of others.\n",
      "- Emergent music: Because each thread carries a musical element, the attraction generates an original, evolving soundtrack â€” a new composition for every day and every hour.\n",
      "- Accessible creativity: The tactile controls and short prompts are designed for kids, seniors, and non-English speakers. Wheelchair-accessible cars and alternate slow-ride loops let everyone participate.\n",
      "\n",
      "Behind the scenes (how itâ€™s feasible)\n",
      "- RFID wristbands link guests to their contributions.\n",
      "- Robotic weaving arms and modular shuttle looms place pre-threaded colored yarns and ribbons (biodegradable and flame-retardant) into a large woven panel in real time.\n",
      "- Projection mapping and a lightweight textile base let new threads be highlighted immediately; an automated embroidery head stitches signatures later.\n",
      "- Sound design engine maps thread choices to musical samples and mixes them in real time into an ambient composition.\n",
      "- Safety: under-6 and more cautious riders can ride in a â€œWeaver Wagonâ€ version with slower speed and an extended weaving demo; all cars have industry-standard restraints and redundant braking.\n",
      "\n",
      "After the ride â€” keepsakes and community\n",
      "- Weaverâ€™s Studio: a hands-on station where you can add a tiny hand-tied tassel to a community wall, order a printed mini-tapestry of the exact slice you helped create, or download the dayâ€™s soundtrack personalized with your contribution.\n",
      "- Daily archive: a high-res photo and audio archive of the tapestry section is posted online and on the park app so guests can return and see how their piece fits into the bigger dream.\n",
      "- Seasonal â€œunweavesâ€: at certain times the park will gently recycle older tapestry sections into wearable scarves or limited-edition park merch that still carries guestsâ€™ embroidered signatures.\n",
      "\n",
      "Emotional payoff\n",
      "Guests leave with more than a thrill â€” they leave with the memory of having shaped something beautiful and public. Families remember arguing over colors, teens love the shareable soundtrack, and artists and children delight in seeing community creativity literally woven together.\n",
      "\n",
      "Poster tagline / slogan\n",
      "Dreamloom â€” Ride the Story. Weave the World.\n"
     ]
    }
   ],
   "source": [
    "medium_prompt = \"Imagine youâ€™ve just been hired as the Chief Imagination Officer for a brand-new amusement park called DreamTopia. Your first assignment is to design the parkâ€™s most unusual and delightful attraction, something that no other park has ever seen before. It should combine at least two completely different ideas (for example: a roller coaster made of books, or a water slide that doubles as a musical instrument). Please describe the attraction in detail: how it looks, how it works, and what makes it magical or fun. End with a short tagline or slogan that could go on the parkâ€™s posters.\"\n",
    "\n",
    "medium_response= chat.completions.create(\n",
    "   model=\"deimos/length-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": medium_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(medium_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed9e93-b099-4325-aa43-199fd74d1687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'length-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'MessageLengthRule',\n",
       "   'rule_name': 'len_rule',\n",
       "   'rule_trigger': 'medium_message_119_tokens',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed112c-6ab6-4a3e-afec-5b225ed79150",
   "metadata": {},
   "source": [
    "## ConversationContextRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0353b465-be4a-4e13-902b-93483ce84399",
   "metadata": {},
   "source": [
    "ConversationContextRule selects model based on the number of back-and-forth messages in a conversation, classifying a conversation as new, developing, or deep.\n",
    "\n",
    "- new conversation: less than `new_threshold` number of messages\n",
    "- developing conversation: between `new_threshold` and `deep_theshold` number of messages\n",
    "- deep conversation: longer than `deep_threshold` number of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3c444b-d09f-4cb9-83a5-438a6c13c798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='context-router', models=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_rule = ConversationContextRule(\n",
    "    name = \"conv-context-rule\",\n",
    "    new_threshold = 3,\n",
    "    deep_threshold = 10,\n",
    "    new_model = \"openai/gpt-5-nano\",\n",
    "    developing_model = \"openai/gpt-4o-mini\",\n",
    "    deep_model = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"context-router\",\n",
    "    rules = [context_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3221777a-4ce9-48e9-9120-09edbc5d30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Deimos, Mars would dominate the sky: Mars would look about 16 degrees across (roughly 32 times bigger than the Moon looks from Earth). So youâ€™d see a gigantic, orange Mars hanging in your sky if you stood on that tiny moon.\n",
      "\n",
      "Quick extra bits:\n",
      "- Deimos is tinyâ€”only about 12 km across.\n",
      "- Itâ€™s thought to be a captured asteroid, not formed around Mars.\n"
     ]
    }
   ],
   "source": [
    "new_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Tell me the funnest fact about Deimos (the moon, not the god).\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(new_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9292e1b-2ee0-4f42-ba31-cf0d7c805229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'context-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'ConversationContextRule',\n",
       "   'rule_name': 'conv-context-rule',\n",
       "   'rule_trigger': 'new_conversation_1_messages_62_chars',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "022cbed9-2c83-4954-bd0c-57d6826cd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Hi there! Can you help me come up with a fun name for a coffee shop?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Of course! How about 'Bean There, Done That'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Haha, thatâ€™s clever. Can you give me a couple more options?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Sure! Some other ideas: 'Daily Grind CafÃ©' and 'Perk Up Coffeehouse.'\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Nice! I like 'Perk Up.' Can you suggest a tagline to go with it?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"How about: 'Perk Up â€” Where Every Cup Sparks Joy'?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Perfect, thatâ€™s exactly what I was looking for. Thanks!\"\n",
    "    }\n",
    "  ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b257399-d65c-4139-a1f7-f4368210850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome! I'm glad you liked it. If you need any more help or ideas, feel free to ask. Good luck with your coffee shop!\n"
     ]
    }
   ],
   "source": [
    "developing_conversation= chat.completions.create(\n",
    "   model=\"deimos/context-router\",\n",
    "   messages=conversation,\n",
    ")\n",
    "\n",
    "print(developing_conversation.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2655be2-7a4d-4c51-a3bd-124eb2076081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'context-router',\n",
       " 'selected_model': 'openai/gpt-4o-mini',\n",
       " 'original_model_field': 'openai/gpt-4o-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'ConversationContextRule',\n",
       "   'rule_name': 'conv-context-rule',\n",
       "   'rule_trigger': 'developing_conversation_7_messages_410_chars',\n",
       "   'decision': 'openai/gpt-4o-mini'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developing_conversation._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544687a-ded6-4384-b7cf-aa4f8bfffd8b",
   "metadata": {},
   "source": [
    "## Custom Rule Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a7a8d-dc7c-4695-94e8-65b40e008bfe",
   "metadata": {},
   "source": [
    "You can create your own custom Rule type by subclassing Rule and implementing `evaluate` with the following signature:\n",
    "\n",
    "```\n",
    "def evaluate(self, request_data: Dict[str, Any]) -> Decision:\n",
    "    # return a Decision\n",
    "```\n",
    "\n",
    "A `Decision` has two arguments, a model str and a trigger str. The trigger str explains why the decision was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e5e9f8-6719-4735-a152-19aab6509197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomRule(Rule):\n",
    "    \"\"\"Selects a model at random.\"\"\"\n",
    "\n",
    "    def __init__(self, name:str, models: list[str]):\n",
    "        super().__init__(name)\n",
    "        \n",
    "        self.models = models\n",
    "\n",
    "    def evaluate(self, _) -> Decision:\n",
    "        model = random.choice(self.models)\n",
    "        return Decision(model, \"random_selection\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "387e0025-972e-49ed-8813-bf1f55c02e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='random-router', models=[])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rule = RandomRule(\n",
    "    name = \"rand-rule\",\n",
    "    models = [\n",
    "        \"openai/gpt-5-nano\",\n",
    "        \"qwen/qwen-turbo\",\n",
    "        \"x-ai/grok-3-mini\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"random-router\",\n",
    "    rules = [rand_rule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1aa4bd9-a5be-4ed4-bc04-7512a9158838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m ChatGPT, an AI assistant created by OpenAI. Hereâ€™s a quick snapshot:\n",
      "\n",
      "- I can help with writing, editing, brainstorming, explaining concepts, summarizing, translating, coding, debugging, planning, and more.\n",
      "- I can adapt my tone and style to be formal, casual, concise, or imaginativeâ€”whatever fits your goal.\n",
      "- I have knowledge up to June 2024 and donâ€™t browse real-time unless a tool is enabled. Some information may be outdated, and I can help verify details or guide you to reliable sources.\n",
      "- I donâ€™t know your personal data unless you share it here, and I donâ€™t retain memory of our chats across sessions unless a memory feature is used.\n",
      "- I generate responses based on patterns in data, not from personal beliefs or experiences, and I can explain my reasoning steps if youâ€™d like a transparent answer (though I can also provide direct results if you prefer).\n",
      "\n",
      "What would you like to work on today?\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'openai/gpt-5-nano', 'original_model_field': 'openai/gpt-5-nano', 'available_models': [], 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'openai/gpt-5-nano'}]}\n",
      "---\n",
      "Iâ€™m ChatGPT, an AI language model from OpenAI. I can help with explanations, writing, brainstorming, coding, summarizing, translating, planning, and more. I generate responses based on patterns in the data I was trained on, not from personal experiences or feelings.\n",
      "\n",
      "A few quick notes:\n",
      "- My knowledge goes up to June 2024, and I donâ€™t browse the web unless you ask me to or a tool is enabled.\n",
      "- I donâ€™t retain personal data between chats unless you share it in this conversation.\n",
      "- I aim to be helpful, accurate, and clear, but I can make mistakesâ€”feel free to correct me.\n",
      "\n",
      "What would you like to do or know today?\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'openai/gpt-5-nano', 'original_model_field': 'openai/gpt-5-nano', 'available_models': [], 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'openai/gpt-5-nano'}]}\n",
      "---\n",
      "Hi, I'm Grok, an AI built by xAI to be as helpful and truthful as possible. I'm inspired by the likes of the Hitchhiker's Guide to the Galaxy, so I try to add a bit of wit to my responses. I'm here to chat about anything from science and tech to random curiositiesâ€”just ask away! What's on your mind? ðŸ˜Š\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'x-ai/grok-3-mini', 'original_model_field': 'x-ai/grok-3-mini', 'available_models': [], 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'x-ai/grok-3-mini'}]}\n",
      "---\n",
      "Well, hello! I'm Grok, an AI assistant created by xAI to be as helpful, truthful, and straightforward as possible. I'm not based on any other companies' modelsâ€”in fact, I'm designed from the ground up to answer questions, spark ideas, and tackle problems with a dash of wit (think Hitchhiker's Guide to the Galaxy vibes). Whether it's explaining complex topics, brainstorming ideas, or just chatting, I'm here to assist. What's on your mindâ€”anything specific you'd like to know? ðŸ˜Š\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'x-ai/grok-3-mini', 'original_model_field': 'x-ai/grok-3-mini', 'available_models': [], 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'x-ai/grok-3-mini'}]}\n",
      "---\n",
      "Hello! I'm Qwen, a large-scale language model developed by Alibaba Group. I can help you with various tasks such as answering questions, creating text, writing code, and more. I have been trained on a vast amount of text data, which allows me to understand and generate text in multiple languages, including Chinese and English. I'm always learning and improving to provide better assistance. How can I help you today?\n",
      "\n",
      "{'router_used': 'random-router', 'selected_model': 'qwen/qwen-turbo', 'original_model_field': 'qwen/qwen-turbo', 'available_models': [], 'explain': [{'rule_type': 'RandomRule', 'rule_name': 'rand-rule', 'rule_trigger': 'random_selection', 'decision': 'qwen/qwen-turbo'}]}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "\n",
    "    prompt = \"Tell me something about yourself.\"\n",
    "\n",
    "    response= chat.completions.create(\n",
    "       model=\"deimos/random-router\",\n",
    "       messages=[\n",
    "           {\"role\": \"user\", \"content\": prompt}\n",
    "       ],\n",
    "    )\n",
    "    \n",
    "    print(response.choices[0].message.content)\n",
    "    print()\n",
    "    print(response._deimos_metadata)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4501990-f1fc-421c-8de6-62196660d901",
   "metadata": {},
   "source": [
    "## Rule Chaining\n",
    "\n",
    "Rules can call other rules instead of models. For example, you might want to first determine if code is present before determining which code language is being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e63a787d-e888-4b7c-94c1-842a830786f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='maybe_code_maybe_not', models=[])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_lang_rule = CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "code_or_not = CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = code_lang_rule,\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Router(\n",
    "    name = \"maybe_code_maybe_not\",\n",
    "    rules = [code_or_not]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3de37fef-6961-48d8-8c93-2a03737dfa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other?\n",
      "\n",
      "They don't have the guts!\n"
     ]
    }
   ],
   "source": [
    "not_code_prompt = \"Tell me a joke.\"\n",
    "\n",
    "not_code_response= chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": not_code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(not_code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "529fa314-94ff-4642-abd6-7f936d76f603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'maybe_code_maybe_not',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a11851ed-48b4-4d45-8552-71bc0b422f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function calculates the nth Fibonacci number using an iterative method that computes the Fibonacci numbers in a binary representation order. It iterates through the binary representation of the input number `n`, and at each step calculates the next Fibonacci numbers based on whether the current bit is 0 or 1. The function then returns the nth Fibonacci number.\n"
     ]
    }
   ],
   "source": [
    "code_prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "code_response = chat.completions.create(\n",
    "   model=\"deimos/maybe_code_maybe_not\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": code_prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(code_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fe48d8f-3fcf-4f22-a1fc-4c8b401d3851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'maybe_code_maybe_not',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'continue'},\n",
       "  {'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e77534-184b-4591-8fd6-9bd46fbd9918",
   "metadata": {},
   "source": [
    "## Rule Fallthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95dd94-3ae0-4dee-a4b7-c3bcb0af0000",
   "metadata": {},
   "source": [
    "You can also list more than one rule in the router. In this case, if the first rule does not match any defined case, the next rule will be used, and so on until a rule that returns a model is found. You can also define a default model on a router, which is used if no rule returns a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baba73eb-a633-4fbe-86c9-3f018734745d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='haiku-but-not-limericks', models=[])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lang_rule = NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"FR\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "auto_task = AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"medical advice\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"haiku-but-not-limericks\",\n",
    "    rules = [nat_lang_rule, auto_task],\n",
    "    default = \"openai/gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e8e826a-56bd-417e-b78d-809231f7cd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deimos, god of dread\n",
      "in war's tremor, he smiles.\n",
      "for courage, fear's lone twin\n"
     ]
    }
   ],
   "source": [
    "haiku_request = \"Write me a short poem with three lines and 17 syllables on Deimos (the god, not the moon).\"\n",
    "\n",
    "haiku_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": haiku_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18aca3ed-39b9-49ba-a65f-f4cc09c492e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'haiku-but-not-limericks',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'no_language_detected',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc9ff723-ddca-46ac-9944-0637d3dd0b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of loops and arrays,  \n",
      "A coder got lost in a daze.  \n",
      "He debugged through the night,  \n",
      "Thinking all was just right,  \n",
      "Till he printed \"ten\" stars in a blaze.\n"
     ]
    }
   ],
   "source": [
    "limerick_request = \"Write a funny five line poem, with AABBA rhyme scheme and a sing-songy meter, about any computer science subject.\"\n",
    "\n",
    "limerick_response = chat.completions.create(\n",
    "   model=\"deimos/haiku-but-not-limericks\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": limerick_request}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(limerick_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e989e052-2dd9-4bc8-8e4b-e91848f37c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'haiku-but-not-limericks',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'no_language_detected',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'no_match'},\n",
       "  {'rule_type': 'default',\n",
       "   'rule_name': 'default',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limerick_response._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c989afb1-9954-433c-b1d8-e50deaba0030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
