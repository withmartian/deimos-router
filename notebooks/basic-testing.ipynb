{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dade040-5d4d-4d1b-a800-091973ab48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deimos_router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f036e4f9-3061-4fb8-a31b-417931dacd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deimos_router import Router, register_router, chat\n",
    "from deimos_router.rules import TaskRule, AutoTaskRule, CodeRule, CodeLanguageRule, NaturalLanguageRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb7434f-ba3e-4154-807a-1cbc293e0328",
   "metadata": {},
   "source": [
    "## Basic Usage - Task Based Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7122b-ca0c-4d4a-baf0-fa395bbdf45f",
   "metadata": {},
   "source": [
    "A Router uses one or more Rules to select a model. The simplest Rule is TaskRule, which maps task names to models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafdefd0-603d-4aac-b5fc-7d437a7cbc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='my-first-router', models=[])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Router(\n",
    "   name=\"my-first-router\",\n",
    "   rules=[\n",
    "       TaskRule(\n",
    "           name=\"task-based-routing\",\n",
    "           triggers={\n",
    "               'coding': 'openai/gpt-5',\n",
    "               'creative': 'openai/gpt-4o',\n",
    "               'simple': 'openai/gpt-5-nano'\n",
    "           }\n",
    "       )\n",
    "   ],\n",
    "   default=\"openai/gpt-4o-mini\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace38270-a991-4ff6-a0f4-d797a20d7df4",
   "metadata": {},
   "source": [
    "To use a Router, make a call to `chat.completions.create`, as if it were a call to OpenAI's SDK, and specify the router as the model.\n",
    "\n",
    "For simple task-based routing, include the task name as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e28bc9-23b5-4d1d-9eee-8faf8c6aedfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n: int) -> int:\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number F_n with F_0 = 0, F_1 = 1.\n",
      "    Uses fast doubling for O(log n) time and O(log n) space.\n",
      "\n",
      "    Args:\n",
      "        n: non-negative integer index\n",
      "\n",
      "    Returns:\n",
      "        F_n as an int\n",
      "\n",
      "    Raises:\n",
      "        TypeError: if n is not an int\n",
      "        ValueError: if n is negative\n",
      "    \"\"\"\n",
      "    if not isinstance(n, int):\n",
      "        raise TypeError(\"n must be a non-negative integer\")\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be non-negative\")\n",
      "\n",
      "    def _dob(k: int) -> tuple[int, int]:\n",
      "        # Returns (F_k, F_{k+1})\n",
      "        if k == 0:\n",
      "            return 0, 1\n",
      "        a, b = _dob(k >> 1)         # a=F_m, b=F_{m+1}, where m = k//2\n",
      "        c = a * ((b << 1) - a)      # F_{2m}\n",
      "        d = a * a + b * b           # F_{2m+1}\n",
      "        if k & 1:\n",
      "            return d, c + d         # (F_{2m+1}, F_{2m+2})\n",
      "        else:\n",
      "            return c, d             # (F_{2m}, F_{2m+1})\n",
      "\n",
      "    return _dob(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response = chat.completions.create(\n",
    "   model=\"deimos/my-first-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d066b713-71df-4584-b305-4115e89b4181",
   "metadata": {},
   "source": [
    "Details about the routing decision can be found in the response at `._deimos_metadata`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13ca7ab1-deec-43fb-a856-675687acebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'my-first-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'TaskRule',\n",
       "   'rule_name': 'task-based-routing',\n",
       "   'rule_trigger': 'coding',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4453-abc1-4850-86e7-56d699d65cbc",
   "metadata": {},
   "source": [
    "## AutoTask Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0d6b54-afde-4e92-918b-544bbc535300",
   "metadata": {},
   "source": [
    "An `AutoTaskRule` is created in the same way as a `TaskRule`, but the task is determined by a call to a small language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a96242-92fa-495c-a269-e9a8163ebae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_task = AutoTaskRule(\n",
    "    name = \"auto-task-rule\",\n",
    "    triggers = {\n",
    "        \"creative writing\" : \"openai/gpt-4o\",\n",
    "        \"writing code\" : \"openai/gpt-5\",\n",
    "        \"informational\" : \"openai/gpt-5-mini\",\n",
    "        \"haiku composition\" : \"openai/gpt-5-nano\"\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e90e8f-19cc-4849-9336-683fbe65443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_router = Router(\n",
    "    name = \"auto-router\",\n",
    "    rules = [auto_task],\n",
    "    default=\"openai/gpt-4o-mini\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b239d0-38f0-4bf3-a404-2020d8780206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fib(n):\n",
      "    \"\"\"\n",
      "    Return the nth Fibonacci number with F(0)=0, F(1)=1 (0-indexed).\n",
      "    Uses fast doubling (O(log n)).\n",
      "    \"\"\"\n",
      "    if n < 0:\n",
      "        raise ValueError(\"n must be >= 0\")\n",
      "\n",
      "    def _fib(k):\n",
      "        if k == 0:\n",
      "            return 0, 1\n",
      "        a, b = _fib(k // 2)\n",
      "        c = a * (2 * b - a)\n",
      "        d = a * a + b * b\n",
      "        if k % 2 == 0:\n",
      "            return c, d\n",
      "        else:\n",
      "            return d, c + d\n",
      "\n",
      "    return _fib(n)[0]\n"
     ]
    }
   ],
   "source": [
    "# Use the router for chat completions\n",
    "response1 = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a python function that finds the nth fibonacci number\"}\n",
    "   ],\n",
    "   task=\"coding\"\n",
    ")\n",
    "\n",
    "print(response1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3492f8f-86a9-4791-a306-27f5d5f02d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'writing code',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "263d7d03-50b7-4f2f-b692-727e5ed4085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あかいほし\n",
      "かせいはゆうひ\n",
      "ゆめのつゆ\n"
     ]
    }
   ],
   "source": [
    "haiku = chat.completions.create(\n",
    "   model=\"deimos/auto-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": \"Write a short japanese poem about mars, and follow the syllable count 5, 7, 5\"}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(haiku.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3f649b-aacb-4dec-9a74-e8ca115cb9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'auto-router',\n",
       " 'selected_model': 'openai/gpt-5-nano',\n",
       " 'original_model_field': 'openai/gpt-5-nano',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'AutoTaskRule',\n",
       "   'rule_name': 'auto-task-rule',\n",
       "   'rule_trigger': 'haiku composition',\n",
       "   'decision': 'openai/gpt-5-nano'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "haiku._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde49483-d23d-4774-8688-e177ccec95a3",
   "metadata": {},
   "source": [
    "## Code / Not code Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e4391-887e-4164-9145-2cf91a5d7cd5",
   "metadata": {},
   "source": [
    "The `CodeRule` is a very simple rule that determines whether a prompt contains code and routes based on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff4960c-efc8-41e0-a822-61e002e230a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_or_not = CodeRule(\n",
    "    name = \"code-or-not-code\",\n",
    "    code = \"openai/gpt-5\",\n",
    "    not_code = \"openai/gpt-4o\"\n",
    ")\n",
    "\n",
    "code_no_code_router = Router(\n",
    "    name = \"code-nocode-router\",\n",
    "    rules = [code_or_not]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e066e5-93ca-4b93-a0cd-2d46ee0c9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You’re using exponentiation (**) instead of multiplication (*).\n",
      "\n",
      "Fixed code:\n",
      "```\n",
      "def multiply(x, y):\n",
      "    return x * y\n",
      "```\n",
      "\n",
      "Quick tests:\n",
      "- multiply(2, 3) -> 6\n",
      "- multiply(-4, 5) -> -20\n",
      "- multiply(2.5, 4) -> 10.0\n",
      "\n",
      "If you actually wanted exponentiation, rename the function or keep x ** y.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Debug this:\n",
    "```\n",
    "def multiply(x, y):\n",
    "    return x**y\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_1 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa69ce97-da19-4b47-80c0-23670255fca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-5',\n",
       " 'original_model_field': 'openai/gpt-5',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'code_detected',\n",
       "   'decision': 'openai/gpt-5'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_1._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a63dcc2-a479-42f1-9504-5cb09256c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mars has two moons, Phobos and Deimos. Of the two, Deimos is the smaller and is often described as the less interesting or less aesthetically appealing. With a diameter of about 12.4 kilometers (7.7 miles), it is irregularly shaped and appears more like an asteroid than a traditional spherical moon. Its surface is covered in dust and loose rocks, and it has fewer large craters compared to Phobos. While beauty is subjective, Deimos is often considered the \"uglier\" moon due to its irregular shape and less dramatic features compared to Phobos.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What is the smallest, ugliest moon of Mars?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "might_be_code_2 = chat.completions.create(\n",
    "   model=\"deimos/code-nocode-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(might_be_code_2.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "471b406c-8d5a-4b1f-be94-60a4d0cb43db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-nocode-router',\n",
       " 'selected_model': 'openai/gpt-4o',\n",
       " 'original_model_field': 'openai/gpt-4o',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeRule',\n",
       "   'rule_name': 'code-or-not-code',\n",
       "   'rule_trigger': 'no_code_detected',\n",
       "   'decision': 'openai/gpt-4o'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "might_be_code_2._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce564b-3e21-4037-bf1d-ef00974c9097",
   "metadata": {},
   "source": [
    "## Code Language Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d74a7c-8067-4299-af77-878bedc65931",
   "metadata": {},
   "source": [
    "To route based on programming language, use a CodeLanguage rule.\n",
    "\n",
    "This rule uses regex to classify among several popular languages, and then falls back to a small language model call to determine language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3137e1d6-9037-4e35-96f4-19937eaa54ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='code-lang-router', models=[])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_lang_rule = CodeLanguageRule(\n",
    "    name = \"code-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"python\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"sql\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"code-lang-router\",\n",
    "    rules = [code_lang_rule]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c4b84c7-9c6f-457f-bc9a-f145c12e5c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function computes the nth Fibonacci number using a technique known as binary exponentiation. It iterates through the binary representation of the input `n` and computes the appropriate Fibonacci numbers based on the current bit in the binary representation. The function then returns the nth Fibonacci number. It raises a `ValueError` if the input `n` is negative.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does this function do?\n",
    "```\n",
    "def _idk(x):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"n must be non-negative\")\n",
    "    a, b = 0, 1  # (F(m), F(m+1))\n",
    "    for bit in bin(n)[2:]:\n",
    "        c = a * (2 * b - a)     # F(2m)\n",
    "        d = a * a + b * b       # F(2m+1)\n",
    "        if bit == '0':\n",
    "            a, b = c, d\n",
    "        else:\n",
    "            a, b = d, c + d\n",
    "    return a\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "179ee0db-bb65-47ed-9062-7cee30f4eb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'python',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b1e0a6-21a2-4655-9119-baaf0f8630c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an SQL query. In plain terms it asks the database to:\n",
      "\n",
      "- Read from the table named people\n",
      "- Return all columns (*) for every row whose name equals \"john\"\n",
      "\n",
      "Notes and caveats:\n",
      "- SQL string literals are normally written with single quotes: WHERE name = 'john'. Some databases (e.g. MySQL in default mode) accept double quotes as string delimiters, but others (e.g. PostgreSQL) treat double quotes as identifiers and will error or behave differently.\n",
      "- Case sensitivity depends on the database and column collation — many setups will match \"John\" and \"john\" the same, some will not.\n",
      "- SELECT * returns every column; for clarity and performance it’s better to list only the columns you need.\n",
      "- For variable input, avoid building queries by concatenation (risk of SQL injection). Use parameterized queries/prepared statements.\n",
      "- If you expect many rows, consider adding LIMIT or an index on name for performance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What does code do?\n",
    "```\n",
    "SELECT *\n",
    "FROM people\n",
    "WHERE name = \"john\"\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "what_it_do = chat.completions.create(\n",
    "   model=\"deimos/code-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(what_it_do.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7b7c6a5-c8fb-4819-9c23-1099a64a8f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'code-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'CodeLanguageRule',\n",
       "   'rule_name': 'code-lang-rule',\n",
       "   'rule_trigger': 'sql',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_it_do._deimos_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994841eb-e468-4447-ad97-de65062189d6",
   "metadata": {},
   "source": [
    "## NaturalLanguageRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f11a8f-8462-4f29-aa3b-55c72d808ac8",
   "metadata": {},
   "source": [
    "To route based on the language of the request (English, French, Spanish, etc), use a NaturalLanguageRule. This calls a small language model to detect the language. Specify language:model mapping using the two-letter ISO language code (`EN`, `FR`, `ES`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75580c2b-bd8d-49c2-a8c9-c1929bf420f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Router(name='nat-lang-router', models=[])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nat_lang_rule = NaturalLanguageRule(\n",
    "    name = \"nat-lang-rule\",\n",
    "    language_mappings = {\n",
    "        \"EN\" : \"openai/gpt-3.5-turbo\",\n",
    "        \"ES\" : \"openai/gpt-5-mini\",\n",
    "    }\n",
    ")\n",
    "\n",
    "Router(\n",
    "    name = \"nat-lang-router\",\n",
    "    rules = [nat_lang_rule]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d51600-d9a8-4fae-91a3-aafe1d629abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the grammar teacher go to the beach?\n",
      "\n",
      "To catch some clauses!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me a joke about language.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65dd159d-c716-450a-bc05-125dc919d627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-3.5-turbo',\n",
       " 'original_model_field': 'openai/gpt-3.5-turbo',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'openai/gpt-3.5-turbo'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4baa8df-1f1f-42a3-8dd9-082d57759356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Sabes por qué el verbo fue al psicólogo? — Porque tenía problemas de concordancia.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Cuéntame un chiste sobre el lenguaje.\n",
    "\"\"\"\n",
    "\n",
    "lang_joke = chat.completions.create(\n",
    "   model=\"deimos/nat-lang-router\",\n",
    "   messages=[\n",
    "       {\"role\": \"user\", \"content\": prompt}\n",
    "   ],\n",
    ")\n",
    "\n",
    "print(lang_joke.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8880aeb8-ae95-4a00-b1cc-a5e0ddb972d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'router_used': 'nat-lang-router',\n",
       " 'selected_model': 'openai/gpt-5-mini',\n",
       " 'original_model_field': 'openai/gpt-5-mini',\n",
       " 'available_models': [],\n",
       " 'explain': [{'rule_type': 'NaturalLanguageRule',\n",
       "   'rule_name': 'nat-lang-rule',\n",
       "   'rule_trigger': 'None',\n",
       "   'decision': 'openai/gpt-5-mini'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_joke._deimos_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b7d72-98b9-4d03-98a1-b5b799837702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
